#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""attention model performance

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WgURLu-n4R0ipX6svtudW0XS90ZaDapZ
"""

# Load the required libraries
import os
import pandas as pd
from tqdm import tqdm
import torch
from transformers import BertTokenizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from models import Deep

import logging

# config variables
mode = 'test'
percent = 10 

LOG_PATH = (f"./logs/deep_{mode}.log")
logging.basicConfig(filename=LOG_PATH, filemode='w', level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
DATA_PATH = './data/feed_data.pt' 

df = pd.read_csv('./data/processed_data.csv')

device = 'cuda' # changable
if device == 'cuda' and torch.cuda.is_available():
    device = torch.device('cuda')
elif device == 'mps' and torch.backends.mps.is_available(): # type: ignore
    device = torch.device('mps')
else:
    device = torch.device('cpu')
logging.debug(f"Computing device: {device}")

# parse inputs
if os.path.isfile(DATA_PATH):
    inputs, labels, author_index, company_index, sentiment_index = torch.load(DATA_PATH)

else:
    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
    df['Item_Author_f'], author_index = pd.factorize(df['Item_Author'])
    df['Company_ID_f'], company_index = pd.factorize(df['Company_ID'])
    df['sentiment_f'], sentiment_index = pd.factorize(df['sentiment'])

    inputs = []
    for index, row in tqdm(df.iterrows(), total=len(df)):
        row_input = []
        # news title [0-31], title mask [32-63]
        title = row['Item_Title']
        encoded_dict = tokenizer.encode_plus(title,
                                            add_special_tokens=True,
                                            max_length=32,
                                            padding='max_length',
                                            truncation=True,
                                            # pad_to_max_length=True,
                                            return_attention_mask=True,
                                            return_tensors='pt')
        row_input.append(encoded_dict['input_ids'].squeeze())
        row_input.append(encoded_dict['attention_mask'].squeeze())
        # news text [64-319], text mask [320-575]
        text = row['news_text']
        encoded_dict = tokenizer.encode_plus(text,
                                            add_special_tokens=True,
                                            max_length=256,
                                            padding='max_length',
                                            truncation=True,
                                            # pad_to_max_length=True,
                                            return_attention_mask=True,
                                            return_tensors='pt')
        row_input.append(encoded_dict['input_ids'].squeeze())
        row_input.append(encoded_dict['attention_mask'].squeeze())
        # author index [576]
        author = row['Item_Author_f']
        row_input.append(torch.tensor([author]))
        # company index [577]
        company = row['Company_ID_f']
        row_input.append(torch.tensor([company]))
        # sentiment index [578]
        sentiment = row['sentiment_f']
        row_input.append(torch.tensor([sentiment]))
        # topic probability [579, 580, 581, 582, 583]
        topics = row[['Topic_1', 'Topic_2', 'Topic_3', 'Topic_4', 'Topic_5']]
        row_input.append(torch.tensor(topics).squeeze())
        row_input = torch.cat(row_input, dim=0)
        # print(row_input.shape) #[1,584]

        inputs.append(row_input)

    inputs = torch.cat(inputs).view(-1,len(row_input))
    print(inputs.shape)

    # label
    labels = torch.tensor(df[f'top{percent}p_views'].values)

    # save procussed data
    torch.save((inputs, labels, author_index, company_index, sentiment_index), DATA_PATH)

# split data
train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(inputs, labels, random_state=42, test_size=0.1)

# setup model
model = Deep(num_author=len(author_index), num_company=len(company_index), num_sentiment=len(sentiment_index), num_topic=5, hidden_size=64)
criterion = torch.nn.CrossEntropyLoss()

# Define the training parameters
batch_size = 16
epochs = 5
learning_rate = 1e-6

# Train the model
if mode == 'train':

    # Load the pre-trained tokenizer and model
    model.to(device)

    # Define the optimizer and loss function
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    logging.debug("Enter Traning")
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for i in range(0, len(train_inputs), batch_size):
            inputs = train_inputs[i:i+batch_size]
            labels = train_labels[i:i+batch_size]

            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            # print(loss)

            train_loss += loss.item()

            loss.backward()
            optimizer.step()
            if i%10000==0:
                logging.debug(f"train:{i}")
        logging.debug(f"train epoch:{epoch}, loss:{train_loss/len(train_inputs)}")

        torch.save(model.state_dict(),f"./models/deep_model_{percent}_{epoch}.pt")

elif mode == 'test':
    logging.debug("enter testing mode")
    for epoch in range(epochs):
        logging.debug(f"{epoch}")
        param = torch.load(f"./models/deep_model_{percent}_{epoch}.pt")
        model.load_state_dict(param)
        model.to(device)
        logging.debug(f"data size: {len(validation_inputs)}")

        # Evaluate the model on the validation set
        model.eval()
        batch_size = 1
        eval_loss = 0
        num_correct = 0
        predictions = []
        true_labels = []
        # attention_weights = []
        with torch.no_grad():
            for i in range(0, len(validation_inputs),batch_size):
                inputs = validation_inputs[i:i+batch_size]
                labels = validation_labels[i:i+batch_size]

                inputs = inputs.to(device)
                labels = labels.to(device)

                outputs = model(inputs)
                loss = criterion(outputs, labels)

                # attn_weights = torch.softmax(outputs.attentions[-1][0], dim=-1).squeeze()
                # attn_value = torch.unsqueeze(attn_weights, 0)

                eval_loss += loss.item()

                _, preds = torch.max(outputs, dim=1)
                # print(outputs[1])
                # print(labels)
                num_correct += torch.sum(preds == labels)
                predictions.extend(preds.cpu().numpy().tolist())
                true_labels.extend(labels.cpu().numpy().tolist())
                
                # attention_df = pd.Series({'text': inputs.cpu().numpy(),
                #                     'label': labels.cpu().numpy(),
                #                     'prediction': preds.cpu().numpy(),
                #                     'attention_weights': attn_value.cpu().numpy()})
                # attention_df.to_frame().T.to_csv(f'./att_results/attention_weights_{percent}_{epoch}.csv', mode='a', index=False, header=False)
                # del attn_weights
                # del attention_df
                # break
                if i%10000==0:
                    logging.debug(f"test:{i}")
                

        # Calculate the accuracy and logging.debug the results
        accuracy = num_correct / len(validation_labels)
        logging.debug(f'Validation Loss: {eval_loss / len(validation_labels):.4f}, Validation Accuracy: {accuracy:.4f}')

        # logging.debug classification report and confusion matrix
        logging.debug(f"\n{classification_report(true_labels, predictions)}")
        confusion_matrix = pd.crosstab(pd.Series(true_labels), pd.Series(predictions), rownames=['True'], colnames=['Predicted'])
        logging.debug(f"\n{confusion_matrix}")
        confusion_matrix.to_csv(f'./att_results/deep confusion matrix_{percent}_{epoch}.csv', index=False)
        # Save attention weights to a CSV file
        # attention_df = pd.DataFrame({'text': validation_inputs.cpu().numpy().tolist(),
        #                             'label': true_labels,
        #                             'prediction': predictions,
        #                             'attention_weights': attention_weights})
        # attention_df.to_csv('./att_results/attention_weights.csv', mode='a', index=False, header=False)