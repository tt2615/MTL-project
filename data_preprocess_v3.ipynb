{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge original data with new sentiment and topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZIQING002\\AppData\\Local\\Temp\\ipykernel_27032\\3862024676.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"./data/eastmoney_bert.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/eastmoney_bert.csv\", usecols=['item_title', 'item_author_cate', 'article_author', 'article_source_cate',\n",
    "       'year', 'month',\n",
    "       'eastmoney_robo_journalism', 'media_robo_journalism', 'SMA_robo_journalism', \n",
    "       'stock_code',\n",
    "       'viral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'item_author', 'article_author', 'article_source',\n",
       "       'item_views', 'item_comment_counts', 'article_likes', 'year', 'month',\n",
       "       'eastmoney_robo_journalism', 'media_robo_journalism',\n",
       "       'SMA_robo_journalism', 'viral', 'article_source_cate',\n",
       "       'item_author_cate', 'sentiment_score', 'cut_titles', 'topics',\n",
       "       'dominant_topic', 'topics_val', 'stock_code', 'topics_val1',\n",
       "       'topics_val2', 'topics_val3', 'topics_val4', 'topics_val5',\n",
       "       'topics_val6', 'topics_val7', 'topics_val8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['item_title', 'item_author_cate', 'article_author', 'article_source_cate',\n",
    "       'year', 'month',\n",
    "       'eastmoney_robo_journalism', 'media_robo_journalism', 'SMA_robo_journalism', \n",
    "       'stock_code',\n",
    "       'viral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment_label'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data = pd.read_csv(\"./lda/sentiment_score.csv\", usecols=['sentiment_label'])\n",
    "sentiment_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = sentiment_data['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'item_author_cate', 'article_author',\n",
       "       'article_source_cate', 'year', 'month', 'eastmoney_robo_journalism',\n",
       "       'media_robo_journalism', 'SMA_robo_journalism', 'stock_code', 'viral',\n",
       "       'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data['year'].astype(int)\n",
    "data['month'] = data['month'].astype(int)\n",
    "data['eastmoney_robo_journalism'] = data['eastmoney_robo_journalism'].astype(int)\n",
    "data['media_robo_journalism'] = data['media_robo_journalism'].astype(int)\n",
    "data['SMA_robo_journalism'] = data['SMA_robo_journalism'].astype(int)\n",
    "data['stock_code'] = data['stock_code'].astype(int)\n",
    "data['dominant_topic'] = data['dominant_topic'].astype(int)\n",
    "data['viral'] = data['viral'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_title</th>\n",
       "      <th>item_author_cate</th>\n",
       "      <th>article_author</th>\n",
       "      <th>article_source_cate</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>eastmoney_robo_journalism</th>\n",
       "      <th>media_robo_journalism</th>\n",
       "      <th>SMA_robo_journalism</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>...</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>topics_val1</th>\n",
       "      <th>topics_val2</th>\n",
       "      <th>topics_val3</th>\n",
       "      <th>topics_val4</th>\n",
       "      <th>topics_val5</th>\n",
       "      <th>topics_val6</th>\n",
       "      <th>topics_val7</th>\n",
       "      <th>topics_val8</th>\n",
       "      <th>viral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6603696</td>\n",
       "      <td>6603696</td>\n",
       "      <td>6603696</td>\n",
       "      <td>6603696</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "      <td>6.603696e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6405069</td>\n",
       "      <td>5158</td>\n",
       "      <td>5800</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>百联股份今日热门盘点</td>\n",
       "      <td>股市胖虎</td>\n",
       "      <td>财智星</td>\n",
       "      <td>东方财富</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>116</td>\n",
       "      <td>426876</td>\n",
       "      <td>3039821</td>\n",
       "      <td>4181680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.021472e+03</td>\n",
       "      <td>6.593989e+00</td>\n",
       "      <td>5.504324e-01</td>\n",
       "      <td>1.353547e-01</td>\n",
       "      <td>2.612287e-01</td>\n",
       "      <td>8.064672e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.003182e+00</td>\n",
       "      <td>1.471907e-01</td>\n",
       "      <td>1.659114e-01</td>\n",
       "      <td>8.226700e-02</td>\n",
       "      <td>1.411012e-01</td>\n",
       "      <td>9.091040e-02</td>\n",
       "      <td>1.278974e-01</td>\n",
       "      <td>1.698810e-01</td>\n",
       "      <td>6.654605e-02</td>\n",
       "      <td>4.778476e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.164505e+00</td>\n",
       "      <td>3.552674e+00</td>\n",
       "      <td>4.974501e-01</td>\n",
       "      <td>3.421020e-01</td>\n",
       "      <td>4.393043e-01</td>\n",
       "      <td>1.316210e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.141182e+00</td>\n",
       "      <td>2.150039e-01</td>\n",
       "      <td>2.016310e-01</td>\n",
       "      <td>1.514186e-01</td>\n",
       "      <td>2.102433e-01</td>\n",
       "      <td>1.822135e-01</td>\n",
       "      <td>2.560611e-01</td>\n",
       "      <td>2.385874e-01</td>\n",
       "      <td>1.471360e-01</td>\n",
       "      <td>2.133105e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.017000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.461144e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.021000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.519547e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.138272e-02</td>\n",
       "      <td>1.251201e-02</td>\n",
       "      <td>1.136303e-02</td>\n",
       "      <td>1.053881e-02</td>\n",
       "      <td>1.043500e-02</td>\n",
       "      <td>1.043842e-02</td>\n",
       "      <td>1.044400e-02</td>\n",
       "      <td>1.043269e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.022000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.821894e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.571400e-02</td>\n",
       "      <td>9.076404e-02</td>\n",
       "      <td>1.254046e-02</td>\n",
       "      <td>1.785633e-02</td>\n",
       "      <td>1.150108e-02</td>\n",
       "      <td>1.175531e-02</td>\n",
       "      <td>1.393731e-02</td>\n",
       "      <td>1.146600e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.022000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.616404e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.799390e-01</td>\n",
       "      <td>2.798150e-01</td>\n",
       "      <td>9.401480e-02</td>\n",
       "      <td>1.914507e-01</td>\n",
       "      <td>9.511740e-02</td>\n",
       "      <td>2.501628e-02</td>\n",
       "      <td>3.471351e-01</td>\n",
       "      <td>2.086633e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.023000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.834914e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>9.485021e-01</td>\n",
       "      <td>9.321075e-01</td>\n",
       "      <td>9.300547e-01</td>\n",
       "      <td>9.299868e-01</td>\n",
       "      <td>9.299970e-01</td>\n",
       "      <td>9.299617e-01</td>\n",
       "      <td>9.299000e-01</td>\n",
       "      <td>9.270756e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_title item_author_cate article_author article_source_cate   \n",
       "count      6603696          6603696        6603696             6603696  \\\n",
       "unique     6405069             5158           5800                 219   \n",
       "top     百联股份今日热门盘点             股市胖虎            财智星                东方财富   \n",
       "freq           116           426876        3039821             4181680   \n",
       "mean           NaN              NaN            NaN                 NaN   \n",
       "std            NaN              NaN            NaN                 NaN   \n",
       "min            NaN              NaN            NaN                 NaN   \n",
       "25%            NaN              NaN            NaN                 NaN   \n",
       "50%            NaN              NaN            NaN                 NaN   \n",
       "75%            NaN              NaN            NaN                 NaN   \n",
       "max            NaN              NaN            NaN                 NaN   \n",
       "\n",
       "                year         month  eastmoney_robo_journalism   \n",
       "count   6.603696e+06  6.603696e+06               6.603696e+06  \\\n",
       "unique           NaN           NaN                        NaN   \n",
       "top              NaN           NaN                        NaN   \n",
       "freq             NaN           NaN                        NaN   \n",
       "mean    2.021472e+03  6.593989e+00               5.504324e-01   \n",
       "std     1.164505e+00  3.552674e+00               4.974501e-01   \n",
       "min     2.017000e+03  1.000000e+00               0.000000e+00   \n",
       "25%     2.021000e+03  4.000000e+00               0.000000e+00   \n",
       "50%     2.022000e+03  7.000000e+00               1.000000e+00   \n",
       "75%     2.022000e+03  1.000000e+01               1.000000e+00   \n",
       "max     2.023000e+03  1.200000e+01               1.000000e+00   \n",
       "\n",
       "        media_robo_journalism  SMA_robo_journalism  sentiment_score  ...   \n",
       "count            6.603696e+06         6.603696e+06     6.603696e+06  ...  \\\n",
       "unique                    NaN                  NaN              NaN  ...   \n",
       "top                       NaN                  NaN              NaN  ...   \n",
       "freq                      NaN                  NaN              NaN  ...   \n",
       "mean             1.353547e-01         2.612287e-01     8.064672e-02  ...   \n",
       "std              3.421020e-01         4.393043e-01     1.316210e-01  ...   \n",
       "min              0.000000e+00         0.000000e+00    -8.461144e-01  ...   \n",
       "25%              0.000000e+00         0.000000e+00     4.519547e-03  ...   \n",
       "50%              0.000000e+00         0.000000e+00     8.821894e-02  ...   \n",
       "75%              0.000000e+00         1.000000e+00     1.616404e-01  ...   \n",
       "max              1.000000e+00         1.000000e+00     9.834914e-01  ...   \n",
       "\n",
       "        dominant_topic   topics_val1   topics_val2   topics_val3   \n",
       "count     6.603696e+06  6.603696e+06  6.603696e+06  6.603696e+06  \\\n",
       "unique             NaN           NaN           NaN           NaN   \n",
       "top                NaN           NaN           NaN           NaN   \n",
       "freq               NaN           NaN           NaN           NaN   \n",
       "mean      4.003182e+00  1.471907e-01  1.659114e-01  8.226700e-02   \n",
       "std       2.141182e+00  2.150039e-01  2.016310e-01  1.514186e-01   \n",
       "min       0.000000e+00  1.000000e-02  0.000000e+00  0.000000e+00   \n",
       "25%       3.000000e+00  1.138272e-02  1.251201e-02  1.136303e-02   \n",
       "50%       5.000000e+00  1.571400e-02  9.076404e-02  1.254046e-02   \n",
       "75%       6.000000e+00  1.799390e-01  2.798150e-01  9.401480e-02   \n",
       "max       7.000000e+00  9.485021e-01  9.321075e-01  9.300547e-01   \n",
       "\n",
       "         topics_val4   topics_val5   topics_val6   topics_val7   topics_val8   \n",
       "count   6.603696e+06  6.603696e+06  6.603696e+06  6.603696e+06  6.603696e+06  \\\n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean    1.411012e-01  9.091040e-02  1.278974e-01  1.698810e-01  6.654605e-02   \n",
       "std     2.102433e-01  1.822135e-01  2.560611e-01  2.385874e-01  1.471360e-01   \n",
       "min     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%     1.053881e-02  1.043500e-02  1.043842e-02  1.044400e-02  1.043269e-02   \n",
       "50%     1.785633e-02  1.150108e-02  1.175531e-02  1.393731e-02  1.146600e-02   \n",
       "75%     1.914507e-01  9.511740e-02  2.501628e-02  3.471351e-01  2.086633e-02   \n",
       "max     9.299868e-01  9.299970e-01  9.299617e-01  9.299000e-01  9.270756e-01   \n",
       "\n",
       "               viral  \n",
       "count   6.603696e+06  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean    4.778476e-02  \n",
       "std     2.133105e-01  \n",
       "min     0.000000e+00  \n",
       "25%     0.000000e+00  \n",
       "50%     0.000000e+00  \n",
       "75%     0.000000e+00  \n",
       "max     1.000000e+00  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['item_author_index'], uniques = pd.factorize(data['item_author_cate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article_author_index'], uniques = pd.factorize(data['article_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article_source_index'], uniques = pd.factorize(data['article_source_cate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stock_code_index'], uniques = pd.factorize(data['stock_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank author info based on past month's stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_54452/2023387980.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./data/eastmoney_topic_sent.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/eastmoney_topic_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'item_author_cate', 'article_author',\n",
       "       'article_source_cate', 'year', 'month', 'eastmoney_robo_journalism',\n",
       "       'media_robo_journalism', 'SMA_robo_journalism', 'stock_code', 'viral',\n",
       "       'sentiment', 'topic', 'item_author_index', 'article_author_index',\n",
       "       'article_source_index', 'stock_code_index', 'year_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'year_month' column for easier handling\n",
    "data['year_month'] = pd.to_datetime(data['year'].astype(str) + '-' + data['month'].astype(str) + '-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_prev_month(data, col):\n",
    "    # Group by 'year', 'month', and col to be ranked to count the number of posts by each author in each month\n",
    "    monthly_count = data.groupby(['year', 'month', col]).size().reset_index(name='post_count')\n",
    "\n",
    "    # Create a shifted version of 'author_monthly_posts' to simulate the \"previous month\"\n",
    "    monthly_count['year_month'] = pd.to_datetime(monthly_count['year'].astype(str) + '-' + monthly_count['month'].astype(str) + '-01')\n",
    "    monthly_count['previous_year_month'] = monthly_count['year_month'] - pd.DateOffset(months=1)\n",
    "\n",
    "    # Split 'previous_year_month' into year and month to prepare for the merge\n",
    "    monthly_count['previous_year'] = monthly_count['previous_year_month'].dt.year\n",
    "    monthly_count['previous_month'] = monthly_count['previous_year_month'].dt.month\n",
    "\n",
    "    # Split 'previous_year_month' into year and month to prepare for the merge\n",
    "    monthly_count['previous_year'] = monthly_count['previous_year_month'].dt.year\n",
    "    monthly_count['previous_month'] = monthly_count['previous_year_month'].dt.month\n",
    "\n",
    "    # Rank authors by their post count within the previous month\n",
    "    monthly_count[f\"{col}_rank\"] = monthly_count.groupby(['previous_year', 'previous_month'])['post_count'].rank(ascending=False, method='dense')\n",
    "\n",
    "    # Merge the rank information back into the original data by matching on 'year', 'month', and 'item_author_index'\n",
    "    data_with_rank = pd.merge(data, \n",
    "                            monthly_count[[col, 'year', 'month', f\"{col}_rank\"]], \n",
    "                            how='left', \n",
    "                            left_on=[col, 'year', 'month'], \n",
    "                            right_on=[col, 'year', 'month'])\n",
    "\n",
    "    # Display the updated data with the author rank in the previous month\n",
    "    print(data_with_rank[['year', 'month', col, f\"{col}_rank\"]])\n",
    "\n",
    "    return data_with_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year  month  item_author_index  item_author_index_rank\n",
      "0        2020      5                  0                     3.0\n",
      "1        2020      8                  1                     2.0\n",
      "2        2020      9                  2                     1.0\n",
      "3        2020      9                  2                     1.0\n",
      "4        2020      9                  2                     1.0\n",
      "...       ...    ...                ...                     ...\n",
      "6603691  2023      8               5111                    55.0\n",
      "6603692  2023      8               5111                    55.0\n",
      "6603693  2023      8               5111                    55.0\n",
      "6603694  2023      8               5111                    55.0\n",
      "6603695  2023      8               5111                    55.0\n",
      "\n",
      "[6603696 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ranked_data = rank_by_prev_month(data, 'item_author_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year  month  article_author_index  article_author_index_rank\n",
      "0        2020      5                     0                        1.0\n",
      "1        2020      8                     0                        1.0\n",
      "2        2020      9                     0                        4.0\n",
      "3        2020      9                     0                        4.0\n",
      "4        2020      9                     0                        4.0\n",
      "...       ...    ...                   ...                        ...\n",
      "6603691  2023      8                     0                        2.0\n",
      "6603692  2023      8                     0                        2.0\n",
      "6603693  2023      8                   453                       49.0\n",
      "6603694  2023      8                     0                        2.0\n",
      "6603695  2023      8                     0                        2.0\n",
      "\n",
      "[6603696 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ranked_data = rank_by_prev_month(ranked_data, 'article_author_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year  month  article_source_index  article_source_index_rank\n",
      "0        2020      5                     0                        1.0\n",
      "1        2020      8                     0                        1.0\n",
      "2        2020      9                     1                        1.0\n",
      "3        2020      9                     1                        1.0\n",
      "4        2020      9                     1                        1.0\n",
      "...       ...    ...                   ...                        ...\n",
      "6603691  2023      8                    30                       14.0\n",
      "6603692  2023      8                    57                       20.0\n",
      "6603693  2023      8                     6                       15.0\n",
      "6603694  2023      8                    21                       21.0\n",
      "6603695  2023      8                    15                        8.0\n",
      "\n",
      "[6603696 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ranked_data = rank_by_prev_month(ranked_data, 'article_source_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'item_author_cate', 'article_author',\n",
       "       'article_source_cate', 'year', 'month', 'eastmoney_robo_journalism',\n",
       "       'media_robo_journalism', 'SMA_robo_journalism', 'stock_code', 'viral',\n",
       "       'sentiment', 'topic', 'item_author_index', 'article_author_index',\n",
       "       'article_source_index', 'stock_code_index', 'year_month',\n",
       "       'item_author_index_rank', 'article_author_index_rank',\n",
       "       'article_source_index_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dim_by_rank(df, col, max_index, max_rank=10):\n",
    "    # Create a mask for rows where the rank exceeds max_rank\n",
    "    mask = df[f\"{col}_rank\"] > max_rank\n",
    "    \n",
    "    # Apply changes only to the rows where the condition is met\n",
    "    df.loc[mask, f\"{col}_rank\"] = max_rank + 1\n",
    "    df.loc[mask, col] = max_index + 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data_with_rank = reduce_dim_by_rank(ranked_data, 'item_author_index', ranked_data['item_author_index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_author_index</th>\n",
       "      <th>item_author_index_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603691</th>\n",
       "      <td>5158</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603692</th>\n",
       "      <td>5158</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603693</th>\n",
       "      <td>5158</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603694</th>\n",
       "      <td>5158</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603695</th>\n",
       "      <td>5158</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6603696 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_author_index  item_author_index_rank\n",
       "0                        0                     3.0\n",
       "1                        1                     2.0\n",
       "2                        2                     1.0\n",
       "3                        2                     1.0\n",
       "4                        2                     1.0\n",
       "...                    ...                     ...\n",
       "6603691               5158                    11.0\n",
       "6603692               5158                    11.0\n",
       "6603693               5158                    11.0\n",
       "6603694               5158                    11.0\n",
       "6603695               5158                    11.0\n",
       "\n",
       "[6603696 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_data_with_rank[['item_author_index', 'item_author_index_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data_with_rank = reduce_dim_by_rank(adj_data_with_rank, col='article_author_index', max_index=ranked_data['article_author_index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_author_index</th>\n",
       "      <th>article_author_index_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603691</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603692</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603693</th>\n",
       "      <td>5800</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603694</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603695</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6603696 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         article_author_index  article_author_index_rank\n",
       "0                           0                        1.0\n",
       "1                           0                        1.0\n",
       "2                           0                        4.0\n",
       "3                           0                        4.0\n",
       "4                           0                        4.0\n",
       "...                       ...                        ...\n",
       "6603691                     0                        2.0\n",
       "6603692                     0                        2.0\n",
       "6603693                  5800                       11.0\n",
       "6603694                     0                        2.0\n",
       "6603695                     0                        2.0\n",
       "\n",
       "[6603696 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_data_with_rank[['article_author_index', 'article_author_index_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data_with_rank = reduce_dim_by_rank(adj_data_with_rank, col='article_source_index', max_index=ranked_data['article_source_index'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_source_index</th>\n",
       "      <th>article_source_index_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603691</th>\n",
       "      <td>219</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603692</th>\n",
       "      <td>219</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603693</th>\n",
       "      <td>219</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603694</th>\n",
       "      <td>219</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603695</th>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6603696 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         article_source_index  article_source_index_rank\n",
       "0                           0                        1.0\n",
       "1                           0                        1.0\n",
       "2                           1                        1.0\n",
       "3                           1                        1.0\n",
       "4                           1                        1.0\n",
       "...                       ...                        ...\n",
       "6603691                   219                       11.0\n",
       "6603692                   219                       11.0\n",
       "6603693                   219                       11.0\n",
       "6603694                   219                       11.0\n",
       "6603695                    15                        8.0\n",
       "\n",
       "[6603696 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_data_with_rank[['article_source_index', 'article_source_index_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'item_author_cate', 'article_author',\n",
       "       'article_source_cate', 'year', 'month', 'eastmoney_robo_journalism',\n",
       "       'media_robo_journalism', 'SMA_robo_journalism', 'stock_code', 'viral',\n",
       "       'sentiment', 'topic', 'item_author_index', 'article_author_index',\n",
       "       'article_source_index', 'stock_code_index', 'year_month',\n",
       "       'item_author_index_rank', 'article_author_index_rank',\n",
       "       'article_source_index_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_data_with_rank.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adj_data_with_rank[['item_title', 'item_author_cate', 'article_author',\n",
    "       'article_source_cate', 'year', 'month', 'eastmoney_robo_journalism',\n",
    "       'media_robo_journalism', 'SMA_robo_journalism', 'stock_code', 'viral',\n",
    "       'sentiment', 'topic', 'item_author_index', 'article_author_index',\n",
    "       'article_source_index', 'stock_code_index', 'year_month',\n",
    "       'item_author_index_rank', 'article_author_index_rank',\n",
    "       'article_source_index_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/eastmoney_ranked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuse industry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_data = pyreadr.read_r('./data/industry_csrc2012_matched.RData')\n",
    "# print(data.keys())\n",
    "ind_data = ind_data[\"industry_csrc2012_matched\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>IndustryCode1</th>\n",
       "      <th>IndustryName1</th>\n",
       "      <th>IndustryCode2</th>\n",
       "      <th>IndustryName2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5410</td>\n",
       "      <td>5410</td>\n",
       "      <td>5410</td>\n",
       "      <td>5410</td>\n",
       "      <td>5410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5016</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>000711</td>\n",
       "      <td>C</td>\n",
       "      <td>制造业</td>\n",
       "      <td>C39</td>\n",
       "      <td>计算机、通信和其他电子设备制造业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3506</td>\n",
       "      <td>3506</td>\n",
       "      <td>586</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock_code IndustryCode1 IndustryName1 IndustryCode2     IndustryName2\n",
       "count        5410          5410          5410          5410              5410\n",
       "unique       5016            19            19            81                81\n",
       "top        000711             C           制造业           C39  计算机、通信和其他电子设备制造业\n",
       "freq            3          3506          3506           586               586"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate entry for the same stock code\n",
    "ind_data = ind_data.drop_duplicates(subset=['stock_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_54452/103470131.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./data/eastmoney_ranked.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/eastmoney_ranked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_data['stock_code'] = ind_data['stock_code'].astype(int)\n",
    "merged_data = data.merge(ind_data, on='stock_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6603696"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['industry_code1_index'], uniques = pd.factorize(merged_data['IndustryCode1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['industry_code2_index'], uniques = pd.factorize(merged_data['IndustryCode2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'item_author_cate', 'article_author',\n",
       "       'article_source_cate', 'year', 'month', 'eastmoney_robo_journalism',\n",
       "       'media_robo_journalism', 'SMA_robo_journalism', 'stock_code', 'viral',\n",
       "       'sentiment', 'topic', 'item_author_index', 'article_author_index',\n",
       "       'article_source_index', 'stock_code_index', 'year_month',\n",
       "       'item_author_index_rank', 'article_author_index_rank',\n",
       "       'article_source_index_rank', 'industry_code1_index',\n",
       "       'industry_code2_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/eastmoney_ranked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data choronologically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/eastmoney_ranked.csv', usecols=['item_title', 'year', 'month', 'eastmoney_robo_journalism',\n",
    "       'media_robo_journalism', 'SMA_robo_journalism', 'viral', 'sentiment', 'topic', 'industry_code1_index', 'industry_code2_index',\n",
    "       'item_author_index', 'article_author_index', 'article_source_index', 'stock_code_index', 'year_month',\n",
    "       'item_author_index_rank', 'article_author_index_rank', 'article_source_index_rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First round:\n",
    "- Train 2017-01-01, 2021.12.13 --> train_bpr1.csv\n",
    "- Valid 2022-01-01, 2022-06-30 --> valid_bpr.csv\n",
    "- Test  2022-07-01, 2022-09-30 --> test1.csv\n",
    "\n",
    "Second round: \n",
    "- Train 2022-07-01, 2022-09-30 --> train_bpr2.csv (test1)\n",
    "- Test  2022-10-01, 2022-12-31 --> test2.csv\n",
    "\n",
    "Third round:\n",
    "- Train 2022-10-01, 2022-12-31 --> train_bpr3.csv (test2)\n",
    "- Test  2023-01-01, 2022-03-31 --> test3.csv\n",
    "\n",
    "Fourth round:\n",
    "- Train 2023-01-01, 2022-03-31 --> train_bpr4.csv\n",
    "- Test  2023-04-01, 2023-08-31 --> test4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first round \n",
    "\n",
    "# Define the date ranges for train, valid, and test sets\n",
    "train1_start = '2017-01-01'\n",
    "train1_end = '2021-12-31'\n",
    "valid1_start = '2022-01-01'\n",
    "valid1_end = '2022-06-30'\n",
    "test1_start = '2022-07-01'\n",
    "test1_end = '2022-09-30'\n",
    "\n",
    "test2_start = '2022-10-01'\n",
    "test2_end = '2022-12-31'\n",
    "\n",
    "test3_start = '2023-01-01'\n",
    "test3_end = '2023-03-31'\n",
    "\n",
    "test4_start = '2023-04-01'\n",
    "test4_end = '2023-08-31'\n",
    "\n",
    "# Split the data based on the defined ranges\n",
    "train_set = data[(data['year_month'] >= train1_start) & (data['year_month'] <= train1_end)]\n",
    "valid_set = data[(data['year_month'] >= valid1_start) & (data['year_month'] <= valid1_end)]\n",
    "test1_set = data[(data['year_month'] >= test1_start) & (data['year_month'] <= test1_end)]\n",
    "test2_set = data[(data['year_month'] >= test2_start) & (data['year_month'] <= test2_end)]\n",
    "test3_set = data[(data['year_month'] >= test3_start) & (data['year_month'] <= test3_end)]\n",
    "test4_set = data[(data['year_month'] >= test4_start) & (data['year_month'] <= test4_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3208461, 1112397, 451944, 423289, 426113, 981492)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(valid_set), len(test1_set), len(test2_set), len(test3_set), len(test4_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259955, 9436, 4506, 9963, 11906, 19790)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set[train_set['viral']==1]), len(valid_set[valid_set['viral']==1]), len(test1_set[test1_set['viral']==1]), len(test2_set[test2_set['viral']==1]), len(test3_set[test3_set['viral']==1]), len(test4_set[test4_set['viral']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(\"./data/train1.csv\", index=False)\n",
    "valid_set.to_csv(\"./data/valid1.csv\", index=False)\n",
    "test1_set.to_csv(\"./data/test1.csv\", index=False)\n",
    "test2_set.to_csv(\"./data/test2.csv\", index=False)\n",
    "test3_set.to_csv(\"./data/test3.csv\", index=False)\n",
    "test4_set.to_csv(\"./data/test4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample negative BPR samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_bpr_train_data(data, dir, aux_data=None):\n",
    "    print(f\"sample negative bpr data and save to {dir}\")\n",
    "    positive_rows = data[data['viral'] == 1]\n",
    "\n",
    "    neg_sample_num = 2\n",
    "    null_count = 0\n",
    "\n",
    "    if aux_data:\n",
    "        # Combine all DataFrames in aux_data with the main DataFrame\n",
    "        combined_df = pd.concat([data] + aux_data, ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        combined_df = data\n",
    "\n",
    "\n",
    "    # Open the output file\n",
    "    with open(dir, 'w', encoding='utf-8') as f:\n",
    "        first_line = True\n",
    "\n",
    "        # Iterate over each positive row\n",
    "        for _, positive_row in tqdm(positive_rows.iterrows(), total=positive_rows.shape[0]):\n",
    "            # Find corresponding negative row based on specified conditions\n",
    "            negative_rows = combined_df[(combined_df['item_author_index'] == positive_row['item_author_index']) &\n",
    "                                (combined_df['article_author_index'] == positive_row['article_author_index']) &\n",
    "                                (combined_df['article_source_index'] == positive_row['article_source_index']) &\n",
    "                                (combined_df['viral'] == 0)]\n",
    "            \n",
    "            # Check if there are valid negative rows\n",
    "            if len(negative_rows)==0:\n",
    "                negative_rows = combined_df[(combined_df['stock_code_index'] == positive_row['stock_code_index']) &\n",
    "                                    (combined_df['viral'] == 0)]\n",
    "                \n",
    "            if len(negative_rows)==0:\n",
    "                null_count+=1\n",
    "                continue\n",
    "\n",
    "            elif len(negative_rows)==1:\n",
    "                neg_samples = negative_rows.iloc[0]\n",
    "                concatenated_row = pd.concat([positive_row, neg_samples.add_prefix('neg_')])\n",
    "                if first_line:\n",
    "                    f.write('<'.join(map(str, concatenated_row.keys()))+'\\n')\n",
    "                    first_line = False\n",
    "\n",
    "                # Write the concatenated row to the file\n",
    "                f.write('<'.join(map(str, concatenated_row.values)) + '\\n')\n",
    "                continue\n",
    "\n",
    "            elif 1<len(negative_rows)<=neg_sample_num:\n",
    "                # Take the first negative row\n",
    "                neg_samples = negative_rows\n",
    "            \n",
    "            elif len(negative_rows)>neg_sample_num:\n",
    "                # Take all negative rows\n",
    "                neg_samples = negative_rows.sample(n=neg_sample_num, replace=False)\n",
    "            \n",
    "            # Iterate over each sampled negative row\n",
    "            for _, negative_row in neg_samples.iterrows():\n",
    "                # Concatenate negative row to positive row with modifications\n",
    "                concatenated_row = pd.concat([positive_row, negative_row.add_prefix('neg_')])\n",
    "\n",
    "                if first_line:\n",
    "                    f.write('<'.join(map(str, concatenated_row.keys()))+'\\n')\n",
    "                    first_line = False\n",
    "\n",
    "                # Write the concatenated row to the file\n",
    "                f.write('<'.join(map(str, concatenated_row.values)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample negative bpr data and save to ./data/train_bpr1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7910/259955 [05:34<5:35:12, 12.53it/s]"
     ]
    }
   ],
   "source": [
    "form_bpr_train_data(train_set, './data/train_bpr1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517533"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_data = pd.read_csv(\"./data/train_bpr1.csv\",delimiter='<')\n",
    "len(bpr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_title', 'year', 'month', 'eastmoney_robo_journalism',\n",
       "       'media_robo_journalism', 'SMA_robo_journalism', 'viral', 'sentiment',\n",
       "       'topic', 'item_author_index', 'article_author_index',\n",
       "       'article_source_index', 'stock_code_index', 'year_month',\n",
       "       'item_author_index_rank', 'article_author_index_rank',\n",
       "       'article_source_index_rank', 'neg_item_title', 'neg_year', 'neg_month',\n",
       "       'neg_eastmoney_robo_journalism', 'neg_media_robo_journalism',\n",
       "       'neg_SMA_robo_journalism', 'neg_viral', 'neg_sentiment', 'neg_topic',\n",
       "       'neg_item_author_index', 'neg_article_author_index',\n",
       "       'neg_article_source_index', 'neg_stock_code_index', 'neg_year_month',\n",
       "       'neg_item_author_index_rank', 'neg_article_author_index_rank',\n",
       "       'neg_article_source_index_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample negative bpr data and save to ./data/valid_bpr.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9436/9436 [08:03<00:00, 19.52it/s]\n"
     ]
    }
   ],
   "source": [
    "form_bpr_train_data(valid_set, './data/valid_bpr.csv',aux_data=[train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18870"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_data = pd.read_csv(\"./data/valid_bpr.csv\",delimiter='<')\n",
    "len(bpr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample negative bpr data and save to ./data/train_bpr2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4506/4506 [04:05<00:00, 18.37it/s]\n"
     ]
    }
   ],
   "source": [
    "form_bpr_train_data(test1_set, './data/train_bpr2.csv',aux_data=[train_set,valid_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9010"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_data = pd.read_csv(\"./data/train_bpr2.csv\",delimiter='<')\n",
    "len(bpr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample negative bpr data and save to ./data/train_bpr3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9963/9963 [10:41<00:00, 15.52it/s]  \n"
     ]
    }
   ],
   "source": [
    "form_bpr_train_data(test2_set, './data/train_bpr3.csv',aux_data=[train_set,valid_set, test1_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_data = pd.read_csv(\"./data/train_bpr3.csv\",delimiter='<')\n",
    "len(bpr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample negative bpr data and save to ./data/train_bpr4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11906/11906 [12:04<00:00, 16.43it/s]\n"
     ]
    }
   ],
   "source": [
    "form_bpr_train_data(test3_set, './data/train_bpr4.csv',aux_data=[train_set,valid_set,test1_set,test2_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23755"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_data = pd.read_csv(\"./data/train_bpr4.csv\",delimiter='<')\n",
    "len(bpr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/eastmoney_ranked.csv', usecols=['item_title', 'year', 'month', 'eastmoney_robo_journalism',\n",
    "       'media_robo_journalism', 'SMA_robo_journalism', 'viral', 'sentiment', 'topic', 'industry_code1_index', 'industry_code2_index',\n",
    "       'item_author_index', 'article_author_index', 'article_source_index', 'stock_code_index', 'year_month',\n",
    "       'item_author_index_rank', 'article_author_index_rank', 'article_source_index_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6603696"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_cols = ['month', \n",
    "                'IndustryCode1',\n",
    "                'IndustryCode2',\n",
    "                'sentiment',\n",
    "                'topic',]\n",
    "author_cols = ['eastmoney_robo_journalism',\n",
    "                'media_robo_journalism',\n",
    "                'SMA_robo_journalism',\n",
    "                'item_author_index',\n",
    "                'article_author_index',\n",
    "                'article_source_index',\n",
    "                'item_author_index_rank',\n",
    "                'article_author_index_rank',\n",
    "                'article_source_index_rank',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'IndustryCode1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/pandas/core/indexes/base.py:3649\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IndustryCode1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#count unique number of each column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m post_unique \u001b[38;5;241m=\u001b[39m [data[x]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m post_cols]\n\u001b[1;32m      3\u001b[0m author_unique \u001b[38;5;241m=\u001b[39m [data[x]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m author_cols]\n",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#count unique number of each column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m post_unique \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m post_cols]\n\u001b[1;32m      3\u001b[0m author_unique \u001b[38;5;241m=\u001b[39m [data[x]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m author_cols]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/pandas/core/frame.py:3745\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3745\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3747\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/pandas/core/indexes/base.py:3651\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IndustryCode1'"
     ]
    }
   ],
   "source": [
    "#count unique number of each column\n",
    "post_unique = [data[x].nunique()+1 for x in post_cols]\n",
    "author_unique = [data[x].nunique()+1 for x in author_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "meta_data = (post_unique, author_unique)\n",
    "with open('meta_data.pkl', 'wb') as f:\n",
    "    pickle.dump(meta_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTL_project-BiIXOKA8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
