{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFI1I2WoeEuL",
        "outputId": "081a4f79-91c6-4ae4-a9c7-63cef44d328f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('./data/full_train_data.csv',)\n",
        "valid_data = pd.read_csv('./data/full_valid_data.csv')\n",
        "test_data = pd.read_csv('./data/full_test_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the column index with the maximum value for each row\n",
        "dominant_topic_index = train_data[['topics_val1', 'topics_val2', 'topics_val3', 'topics_val4', 'topics_val5']].idxmax(axis=1)\n",
        "\n",
        "# Convert column index to categorical number (1 to 5)\n",
        "train_data['dominant_topics'] = dominant_topic_index.str.extract('(\\d+)').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the column index with the maximum value for each row\n",
        "dominant_topic_index = test_data[['topics_val1', 'topics_val2', 'topics_val3', 'topics_val4', 'topics_val5']].idxmax(axis=1)\n",
        "\n",
        "# Convert column index to categorical number (1 to 5)\n",
        "test_data['dominant_topics'] = dominant_topic_index.str.extract('(\\d+)').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['item_title', 'item_author_cate', 'article_author',\n",
              "       'article_source_cate', 'month', 'eastmoney_robo_journalism',\n",
              "       'media_robo_journalism', 'SMA_robo_journalism', 'viral',\n",
              "       'sentiment_score', 'topics_val1', 'topics_val2', 'topics_val3',\n",
              "       'topics_val4', 'topics_val5', 'stock_code', 'IndustryCode1',\n",
              "       'IndustryName1', 'IndustryCode2', 'IndustryName2',\n",
              "       'item_author_reduced', 'article_author_reduced',\n",
              "       'article_source_reduced', 'stock_code_index', 'item_author_cate_index',\n",
              "       'article_author_index', 'article_source_cate_index', 'month_index',\n",
              "       'IndustryCode1_index', 'IndustryCode2_index',\n",
              "       'eastmoney_robo_journalism_index', 'media_robo_journalism_index',\n",
              "       'SMA_robo_journalism_index', 'item_author_reduced_index',\n",
              "       'article_author_reduced_index', 'article_source_reduced_index',\n",
              "       'neg_item_title', 'neg_item_author_cate', 'neg_article_author',\n",
              "       'neg_article_source_cate', 'neg_month', 'neg_eastmoney_robo_journalism',\n",
              "       'neg_media_robo_journalism', 'neg_SMA_robo_journalism', 'neg_viral',\n",
              "       'neg_sentiment_score', 'neg_topics_val1', 'neg_topics_val2',\n",
              "       'neg_topics_val3', 'neg_topics_val4', 'neg_topics_val5',\n",
              "       'neg_stock_code', 'neg_IndustryCode1', 'neg_IndustryName1',\n",
              "       'neg_IndustryCode2', 'neg_IndustryName2', 'neg_item_author_reduced',\n",
              "       'neg_article_author_reduced', 'neg_article_source_reduced',\n",
              "       'neg_stock_code_index', 'neg_item_author_cate_index',\n",
              "       'neg_article_author_index', 'neg_article_source_cate_index',\n",
              "       'neg_month_index', 'neg_IndustryCode1_index', 'neg_IndustryCode2_index',\n",
              "       'neg_eastmoney_robo_journalism_index',\n",
              "       'neg_media_robo_journalism_index', 'neg_SMA_robo_journalism_index',\n",
              "       'neg_item_author_reduced_index', 'neg_article_author_reduced_index',\n",
              "       'neg_article_source_reduced_index', 'dominant_topics'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_list = ['month_index', \n",
        "            'eastmoney_robo_journalism_index', \n",
        "            'media_robo_journalism_index', \n",
        "            'SMA_robo_journalism_index',\n",
        "            'sentiment_score',\n",
        "            'stock_code_index', \n",
        "            'IndustryCode1_index',\n",
        "            'IndustryCode2_index',\n",
        "            'dominant_topics',\n",
        "            'item_author_reduced_index', \n",
        "            'article_author_reduced_index',\n",
        "            'article_source_reduced_index']\n",
        "\n",
        "# 划分特征和目标变量\n",
        "train_x = train_data[input_list]\n",
        "train_y = train_data['viral']\n",
        "# valid_x = valid_data[input_list]\n",
        "# valid_y = valid_data['viral']\n",
        "test_x = test_data[input_list]\n",
        "test_y = test_data['viral']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['month_index'] = le.fit_transform(train_x['month_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['eastmoney_robo_journalism_index'] = le.fit_transform(train_x['eastmoney_robo_journalism_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['media_robo_journalism_index'] = le.fit_transform(train_x['media_robo_journalism_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['stock_code_index'] = le.fit_transform(train_x['stock_code_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['IndustryCode1_index'] = le.fit_transform(train_x['IndustryCode1_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['IndustryCode2_index'] = le.fit_transform(train_x['IndustryCode2_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['dominant_topics'] = le.fit_transform(train_x['dominant_topics'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['item_author_reduced_index'] = le.fit_transform(train_x['item_author_reduced_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['article_author_reduced_index'] = le.fit_transform(train_x['article_author_reduced_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_x['article_source_reduced_index'] = le.fit_transform(train_x['article_source_reduced_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['month_index'] = le.fit_transform(test_x['month_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['eastmoney_robo_journalism_index'] = le.fit_transform(test_x['eastmoney_robo_journalism_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['media_robo_journalism_index'] = le.fit_transform(test_x['media_robo_journalism_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['stock_code_index'] = le.fit_transform(test_x['stock_code_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['IndustryCode1_index'] = le.fit_transform(test_x['IndustryCode1_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['IndustryCode2_index'] = le.fit_transform(test_x['IndustryCode2_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['dominant_topics'] = le.fit_transform(test_x['dominant_topics'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['item_author_reduced_index'] = le.fit_transform(test_x['item_author_reduced_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['article_author_reduced_index'] = le.fit_transform(test_x['article_author_reduced_index'].astype(int))\n",
            "/var/folders/52/5ygfc9d94sscvjzdx8yvt2sm0000gq/T/ipykernel_71286/2778505005.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_x['article_source_reduced_index'] = le.fit_transform(test_x['article_source_reduced_index'].astype(int))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# cat_col_list = ['month_index', \n",
        "#             'eastmoney_robo_journalism_index', \n",
        "#             'media_robo_journalism_index', \n",
        "#             'SMA_robo_journalism_index',\n",
        "#             'stock_code_index', \n",
        "#             'IndustryCode1_index',\n",
        "#             'IndustryCode2_index',\n",
        "#             'dominant_topics',\n",
        "#             'item_author_reduced_index', \n",
        "#             'article_author_reduced_index',\n",
        "#             'article_source_reduced_index']\n",
        "\n",
        "train_x['month_index'] = le.fit_transform(train_x['month_index'].astype(int))\n",
        "train_x['eastmoney_robo_journalism_index'] = le.fit_transform(train_x['eastmoney_robo_journalism_index'].astype(int))\n",
        "train_x['media_robo_journalism_index'] = le.fit_transform(train_x['media_robo_journalism_index'].astype(int))\n",
        "train_x['stock_code_index'] = le.fit_transform(train_x['stock_code_index'].astype(int))\n",
        "train_x['IndustryCode1_index'] = le.fit_transform(train_x['IndustryCode1_index'].astype(int))\n",
        "train_x['IndustryCode2_index'] = le.fit_transform(train_x['IndustryCode2_index'].astype(int))\n",
        "train_x['dominant_topics'] = le.fit_transform(train_x['dominant_topics'].astype(int))\n",
        "train_x['item_author_reduced_index'] = le.fit_transform(train_x['item_author_reduced_index'].astype(int))\n",
        "train_x['article_author_reduced_index'] = le.fit_transform(train_x['article_author_reduced_index'].astype(int))\n",
        "train_x['article_source_reduced_index'] = le.fit_transform(train_x['article_source_reduced_index'].astype(int))\n",
        "\n",
        "test_x['month_index'] = le.fit_transform(test_x['month_index'].astype(int))\n",
        "test_x['eastmoney_robo_journalism_index'] = le.fit_transform(test_x['eastmoney_robo_journalism_index'].astype(int))\n",
        "test_x['media_robo_journalism_index'] = le.fit_transform(test_x['media_robo_journalism_index'].astype(int))\n",
        "test_x['stock_code_index'] = le.fit_transform(test_x['stock_code_index'].astype(int))\n",
        "test_x['IndustryCode1_index'] = le.fit_transform(test_x['IndustryCode1_index'].astype(int))\n",
        "test_x['IndustryCode2_index'] = le.fit_transform(test_x['IndustryCode2_index'].astype(int))\n",
        "test_x['dominant_topics'] = le.fit_transform(test_x['dominant_topics'].astype(int))\n",
        "test_x['item_author_reduced_index'] = le.fit_transform(test_x['item_author_reduced_index'].astype(int))\n",
        "test_x['article_author_reduced_index'] = le.fit_transform(test_x['article_author_reduced_index'].astype(int))\n",
        "test_x['article_source_reduced_index'] = le.fit_transform(test_x['article_source_reduced_index'].astype(int))\n",
        "\n",
        "\n",
        "# train_x[cat_col_list] = le.fit_transform(train_x[cat_col_list])\n",
        "train_y = le.fit_transform(train_y)\n",
        "# test_x[cat_col_list] = le.fit_transform(test_x[cat_col_list])\n",
        "test_y = le.fit_transform(test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4It742M82E"
      },
      "source": [
        "# Use machine learning models to predict virality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPW1-BTAuf_B"
      },
      "source": [
        "## XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK8d03bH3jya",
        "outputId": "a231280e-ef5f-4604-a35e-008cd7a2a98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=1.000 total time=   0.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=1.000 total time=   0.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=1.000 total time=   0.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=1.000 total time=   0.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=1.000 total time=   0.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=1.000 total time=   0.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=1.000 total time=   0.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=1.000 total time=   0.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=1.000 total time=   0.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=1.000 total time=   0.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=1.000 total time=   0.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=1.000 total time=   0.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=1.000 total time=   0.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=1.000 total time=   0.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=1.000 total time=   0.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=1.000 total time=   0.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=1.000 total time=   0.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=1.000 total time=   0.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=1.000 total time=   0.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=1.000 total time=   0.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=1.000 total time=   0.3s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[62], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 设置GridSearchCV\u001b[39;00m\n\u001b[1;32m     23\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model1, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 使用最佳参数的模型\u001b[39;00m\n\u001b[1;32m     27\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ndcg_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "\n",
        "# 初始化分类器\n",
        "model1 = xgb.XGBClassifier()\n",
        "\n",
        "# 参数网格\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.3, 0.5, 0.7]\n",
        "    }\n",
        "\n",
        "# 设置GridSearchCV\n",
        "grid_search = GridSearchCV(model1, param_grid, scoring='accuracy', cv=3, verbose=3)\n",
        "grid_search.fit(train_x, train_y)\n",
        "\n",
        "# 使用最佳参数的模型\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 建立XGBoost模型\n",
        "# 从GridSearchCV获得最佳参数设置\n",
        "model1 = xgb.XGBClassifier(\n",
        "    learning_rate=best_model.learning_rate,\n",
        "    n_estimators=best_model.n_estimators,\n",
        "    max_depth= best_model.max_depth,\n",
        "    subsample=best_model.subsample,\n",
        "    colsample_bytree=best_model.colsample_bytree\n",
        "    )\n",
        "model1.fit(train_x, train_y)\n",
        "\n",
        "# 预测\n",
        "test_pred = model1.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jendT_z7NFt-",
        "outputId": "be5ceacb-6611-4ef3-b0c8-5cb007d102b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      6354\n",
            "           1       0.00      0.00      0.00        46\n",
            "\n",
            "    accuracy                           0.99      6400\n",
            "   macro avg       0.50      0.50      0.50      6400\n",
            "weighted avg       0.99      0.99      0.99      6400\n",
            "\n",
            "Confusion Matrix:\n",
            " [[6354    0]\n",
            " [  46    0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# 评估：accuracy\n",
        "print(\"Classification Report:\\n\", classification_report(test_y, test_pred))\n",
        "conf_matrix = confusion_matrix(test_y, test_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NDCG@1:\n",
            " 0.0071875\n",
            "NDCG@5:\n",
            " 0.007187499999999999\n",
            "NDCG@10:\n",
            " 0.0071875\n",
            "NDCG:\n",
            " 0.3458997499253763\n"
          ]
        }
      ],
      "source": [
        "# 评估：ndcg\n",
        "print(\"NDCG@1:\\n\", ndcg_score([test_y], [test_pred], k=1))\n",
        "print(\"NDCG@5:\\n\", ndcg_score([test_y], [test_pred], k=5))\n",
        "print(\"NDCG@10:\\n\", ndcg_score([test_y], [test_pred], k=10))\n",
        "print(\"NDCG:\\n\", ndcg_score([test_y], [test_pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOQC5mGwNjaM"
      },
      "source": [
        "Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDljE9io3nPE",
        "outputId": "7694cab6-0852-4fdb-9f36-85b4420ad376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('month_index', 0.0), ('eastmoney_robo_journalism_index', 0.0), ('media_robo_journalism_index', 0.0), ('SMA_robo_journalism_index', 0.0), ('sentiment_score', 0.0), ('stock_code_index', 0.0), ('IndustryCode1_index', 0.0), ('IndustryCode2_index', 0.0), ('dominant_topics', 0.0), ('item_author_reduced_index', 0.0), ('article_author_reduced_index', 0.0), ('article_source_reduced_index', 0.0)]\n"
          ]
        }
      ],
      "source": [
        "# 获取特征的重要性\n",
        "feature_importance = model1.feature_importances_\n",
        "\n",
        "# 将特征重要性与特征名称进行配对，并排序\n",
        "feature_importance_dict = dict(zip(test_x.columns, feature_importance))\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 打印特征重要性\n",
        "print(\"Feature importances:\\n\", sorted_feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkxU6OZiuq2-"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHBdohdxNwjR"
      },
      "source": [
        "Due to network issues, the process of choosing best hyparameters was run in three separate runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4508Ce0aev-i",
        "outputId": "ca5afeab-592e-46ce-e523-4d649569b219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing 50 trees with max depth of 10. Mean CV Accuracy: 1.0\n",
            "Testing 80 trees with max depth of 10. Mean CV Accuracy: 1.0\n",
            "Testing 100 trees with max depth of 10. Mean CV Accuracy: 1.0\n",
            "Testing 150 trees with max depth of 10. Mean CV Accuracy: 1.0\n",
            "Testing 200 trees with max depth of 10. Mean CV Accuracy: 1.0\n",
            "Testing 50 trees with max depth of 20. Mean CV Accuracy: 1.0\n",
            "Testing 80 trees with max depth of 20. Mean CV Accuracy: 1.0\n",
            "Testing 100 trees with max depth of 20. Mean CV Accuracy: 1.0\n",
            "Testing 150 trees with max depth of 20. Mean CV Accuracy: 1.0\n",
            "Testing 200 trees with max depth of 20. Mean CV Accuracy: 1.0\n",
            "Testing 50 trees with max depth of 30. Mean CV Accuracy: 1.0\n",
            "Testing 80 trees with max depth of 30. Mean CV Accuracy: 1.0\n",
            "Testing 100 trees with max depth of 30. Mean CV Accuracy: 1.0\n",
            "Testing 150 trees with max depth of 30. Mean CV Accuracy: 1.0\n",
            "Testing 200 trees with max depth of 30. Mean CV Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 参数范围设置\n",
        "max_depth_options = [10, 20, 30]\n",
        "n_estimators_options = [50, 80, 100, 150, 200]\n",
        "\n",
        "best_score = 0\n",
        "best_params = {'max_depth': None, 'n_estimators': 100}\n",
        "\n",
        "for max_depth in max_depth_options:\n",
        "    for n_estimators in n_estimators_options:\n",
        "        # 初始化随机森林分类器\n",
        "        model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "        # 使用交叉验证计算评分\n",
        "        scores = cross_val_score(model, train_x, train_y, cv=5, scoring='accuracy')\n",
        "        average_score = np.mean(scores)\n",
        "\n",
        "        print(f\"Testing {n_estimators} trees with max depth of {max_depth}. Mean CV Accuracy: {average_score}\")\n",
        "\n",
        "        # 检查并更新最佳得分和参数\n",
        "        if average_score > best_score:\n",
        "            best_score = average_score\n",
        "            best_params = {'max_depth': max_depth, 'n_estimators': n_estimators}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heYus-N7nVWo",
        "outputId": "4f30de63-75e2-4325-e004-6266f5f6fc18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      6354\n",
            "           1       0.00      0.00      0.00        46\n",
            "\n",
            "    accuracy                           0.99      6400\n",
            "   macro avg       0.50      0.50      0.50      6400\n",
            "weighted avg       0.99      0.99      0.99      6400\n",
            "\n",
            "Confusion Matrix:\n",
            " [[6354    0]\n",
            " [  46    0]]\n",
            "NDCG@1:\n",
            " 0.0071875\n",
            "NDCG@5:\n",
            " 0.007187499999999999\n",
            "NDCG@10:\n",
            " 0.0071875\n",
            "NDCG:\n",
            " 0.3458997499253763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# 使用最佳参数训练模型\n",
        "best_model = RandomForestClassifier(max_depth=20, n_estimators=80, random_state=42)\n",
        "best_model.fit(train_x, train_y)\n",
        "test_pred = best_model.predict(test_x)\n",
        "\n",
        "# 评估\n",
        "print(\"Classification Report:\\n\", classification_report(test_y, test_pred))\n",
        "conf_matrix = confusion_matrix(test_y, test_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# 评估：ndcg\n",
        "print(\"NDCG@1:\\n\", ndcg_score([test_y], [test_pred], k=1))\n",
        "print(\"NDCG@5:\\n\", ndcg_score([test_y], [test_pred], k=5))\n",
        "print(\"NDCG@10:\\n\", ndcg_score([test_y], [test_pred], k=10))\n",
        "print(\"NDCG:\\n\", ndcg_score([test_y], [test_pred]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAnSNvrUfGYM",
        "outputId": "3cab5283-40ff-4b6d-8941-c50afca8ce62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('month_index', 0.0), ('eastmoney_robo_journalism_index', 0.0), ('media_robo_journalism_index', 0.0), ('SMA_robo_journalism_index', 0.0), ('sentiment_score', 0.0), ('stock_code_index', 0.0), ('IndustryCode1_index', 0.0), ('IndustryCode2_index', 0.0), ('dominant_topics', 0.0), ('item_author_reduced_index', 0.0), ('article_author_reduced_index', 0.0), ('article_source_reduced_index', 0.0)]\n"
          ]
        }
      ],
      "source": [
        "# 获取特征的重要性\n",
        "feature_importance = best_model.feature_importances_\n",
        "\n",
        "# 将特征重要性与特征名称进行配对，并排序\n",
        "feature_importance_dict = dict(zip(test_x, feature_importance))\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Feature importances:\\n\", sorted_feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apgEzYA3BH0i"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dp41YRT7SJQ"
      },
      "source": [
        "Add class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_list = ['month_index', \n",
        "            'eastmoney_robo_journalism_index', \n",
        "            'media_robo_journalism_index', \n",
        "            'SMA_robo_journalism_index',\n",
        "            'stock_code_index', \n",
        "            'IndustryCode1_index',\n",
        "            'IndustryCode2_index',\n",
        "            'dominant_topics',\n",
        "            'item_author_reduced_index', \n",
        "            'article_author_reduced_index',\n",
        "            'article_source_reduced_index']\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "train_x_onehot, test_x_onehot = train_x, test_x\n",
        "\n",
        "for col in input_list:\n",
        "    col_onehot = encoder.fit_transform(train_x_onehot[[col]])\n",
        "    encoded_df = pd.DataFrame(col_onehot, columns=[f\"{col}_{i}\" for i in range(col_onehot.shape[1])])\n",
        "    train_x_onehot = pd.concat([train_x_onehot.drop(col, axis=1), encoded_df], axis=1)\n",
        "\n",
        "for col in input_list:\n",
        "    col_onehot = encoder.fit_transform(test_x_onehot[[col]])\n",
        "    encoded_df = pd.DataFrame(col_onehot, columns=[f\"{col}_{i}\" for i in range(col_onehot.shape[1])])\n",
        "    test_x_onehot = pd.concat([test_x_onehot.drop(col, axis=1), encoded_df], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['sentiment_score', 'month_index_0', 'month_index_1', 'month_index_2',\n",
              "       'month_index_3', 'month_index_4', 'month_index_5', 'month_index_6',\n",
              "       'month_index_7', 'month_index_8',\n",
              "       ...\n",
              "       'item_author_reduced_index_5', 'item_author_reduced_index_6',\n",
              "       'item_author_reduced_index_7', 'item_author_reduced_index_8',\n",
              "       'item_author_reduced_index_9', 'article_author_reduced_index_0',\n",
              "       'article_source_reduced_index_0', 'article_source_reduced_index_1',\n",
              "       'article_source_reduced_index_2', 'article_source_reduced_index_3'],\n",
              "      dtype='object', length=183)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x_onehot.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJEIaLrNBNFA",
        "outputId": "c5652f5c-bec4-45f2-82a8-6035d68afcf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.992 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.992 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.994 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.991 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.992 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.996 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.992 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.992 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.995 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.996 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.991 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.996 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.991 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.990 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.989 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.989 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.996 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.989 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.989 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.989 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.989 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.988 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.8s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.989 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.989 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.989 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.996 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.989 total time=   1.7s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.988 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.3, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.992 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.992 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.992 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.992 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.992 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.992 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.992 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.992 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.992 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.992 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.992 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.991 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.991 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.996 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.991 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.995 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.994 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.996 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.989 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.8s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.989 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.989 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.996 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.996 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.989 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.989 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.989 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.989 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.996 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.989 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.989 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.989 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.989 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.989 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.994 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.996 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.989 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.5, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.992 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.992 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.992 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.992 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.992 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.8s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.992 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.8s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.992 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.992 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.2s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.992 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.992 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.992 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.992 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.992 total time=   1.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.992 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=0.993 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.991 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=0.996 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=0.996 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.995 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8;, score=0.996 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=0.996 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0;, score=0.996 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=0.996 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.994 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=0.996 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=0.996 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=0.995 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9;, score=0.995 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.990 total time=   1.1s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.994 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=0.996 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=0.996 total time=   1.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.991 total time=   0.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.990 total time=   0.8s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.994 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.7s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.7s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0;, score=0.996 total time=   0.7s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0;, score=0.996 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.995 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.990 total time=   0.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.5s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0;, score=0.996 total time=   0.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.989 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9;, score=0.995 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.990 total time=   0.9s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0;, score=0.996 total time=   0.9s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.989 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.2s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9;, score=0.995 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.3s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0;, score=0.994 total time=   1.3s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.9;, score=0.994 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.990 total time=   0.6s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.994 total time=   0.6s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0;, score=0.995 total time=   0.6s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8;, score=0.995 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.9;, score=0.994 total time=   1.0s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.990 total time=   1.0s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.994 total time=   1.0s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0;, score=0.995 total time=   1.1s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.990 total time=   1.5s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8;, score=0.995 total time=   1.4s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.990 total time=   1.3s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.994 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.9;, score=0.993 total time=   1.5s\n",
            "[CV 1/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.990 total time=   1.4s\n",
            "[CV 2/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.993 total time=   1.4s\n",
            "[CV 3/3] END colsample_bytree=0.7, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0;, score=0.995 total time=   1.5s\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV 1/3] END C=0.0001, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 2/3] END C=0.0001, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 3/3] END C=0.0001, penalty=l2, solver=liblinear;, score=0.993 total time=   0.3s\n",
            "[CV 1/3] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.3s\n",
            "[CV 2/3] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.0s\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.993 total time=   0.0s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.7s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.6s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.993 total time=   0.0s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.0s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.1s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.2s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.993 total time=   0.0s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.993 total time=   0.2s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.8s\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.9s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.9s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.993 total time=   0.2s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.4s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.8s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.993 total time=   1.6s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.991 total time=   0.1s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.993 total time=   0.1s\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.992 total time=   0.1s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.991 total time=   3.1s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.993 total time=   3.3s\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.992 total time=   2.9s\n",
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.988 total time=   0.1s\n",
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.992 total time=   0.1s\n",
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.991 total time=   0.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.989 total time=   4.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.992 total time=   4.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.991 total time=   4.6s\n",
            "[CV 1/3] END C=166.81005372000558, penalty=l2, solver=liblinear;, score=0.989 total time=   0.2s\n",
            "[CV 2/3] END C=166.81005372000558, penalty=l2, solver=liblinear;, score=0.990 total time=   0.3s\n",
            "[CV 3/3] END C=166.81005372000558, penalty=l2, solver=liblinear;, score=0.989 total time=   0.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=166.81005372000558, penalty=l2, solver=lbfgs;, score=0.989 total time=   4.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=166.81005372000558, penalty=l2, solver=lbfgs;, score=0.990 total time=   4.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=166.81005372000558, penalty=l2, solver=lbfgs;, score=0.989 total time=   3.6s\n",
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.987 total time=   0.2s\n",
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.990 total time=   0.2s\n",
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.990 total time=   0.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.988 total time=   4.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.990 total time=   4.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.989 total time=   4.3s\n",
            "[CV 1/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.988 total time=   0.2s\n",
            "[CV 2/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.989 total time=   0.2s\n",
            "[CV 3/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.990 total time=   0.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.988 total time=   5.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.989 total time=   4.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.990 total time=   4.6s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# 对 dominant_topic 进行独热编码\n",
        "\n",
        "\n",
        "# 标准化\n",
        "scaler = StandardScaler()\n",
        "sentiment_scores = train_x_onehot['sentiment_score'].values.reshape(-1, 1)\n",
        "train_x_onehot['sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
        "\n",
        "# 计算类权重\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_y_onehot), y=train_y_onehot)\n",
        "weights = {i : class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# 将类权重添加到逻辑回归模型\n",
        "logistic_model = LogisticRegression(class_weight=weights)\n",
        "\n",
        "# 可能选择更多特征\n",
        "selector = RFE(logistic_model, n_features_to_select=5, step=1)\n",
        "selector.fit(train_x_onehot, train_y) ##TO CHANGE!\n",
        "# grid_search.fit(test_x_onehot, test_y)\n",
        "\n",
        "# 定义要搜索的参数网格\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 10),\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "# 设置GridSearchCV\n",
        "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
        "grid_search.fit(train_x_onehot, train_y) ##TO CHANGE!\n",
        "# grid_search.fit(test_x_onehot, test_y)\n",
        "\n",
        "# 使用最佳参数的模型\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 预测\n",
        "test_pred = best_model.predict(test_x_onehot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ9QalCnwDKu",
        "outputId": "f770840c-21ff-4796-d289-9227cb5f68cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      1.00      6354\n",
            "         1.0       0.00      0.00      0.00        46\n",
            "\n",
            "    accuracy                           0.99      6400\n",
            "   macro avg       0.50      0.50      0.50      6400\n",
            "weighted avg       0.99      0.99      0.99      6400\n",
            "\n",
            "Confusion Matrix:\n",
            " [[6354    0]\n",
            " [  46    0]]\n",
            "NDCG@1:\n",
            " 0.0071875\n",
            "NDCG@5:\n",
            " 0.007187499999999999\n",
            "NDCG@10:\n",
            " 0.0071875\n",
            "NDCG:\n",
            " 0.3458997499253763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/wuziqing/.local/share/virtualenvs/MTL_project-BiIXOKA8/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# 评估\n",
        "print(\"Classification Report:\\n\", classification_report(test_y, test_pred))\n",
        "conf_matrix = confusion_matrix(test_y, test_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# 评估：ndcg\n",
        "print(\"NDCG@1:\\n\", ndcg_score([test_y], [test_pred], k=1))\n",
        "print(\"NDCG@5:\\n\", ndcg_score([test_y], [test_pred], k=5))\n",
        "print(\"NDCG@10:\\n\", ndcg_score([test_y], [test_pred], k=10))\n",
        "print(\"NDCG:\\n\", ndcg_score([test_y], [test_pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RVm1BTeOWBQ"
      },
      "source": [
        "Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=LogisticRegression(class_weight={0: 1.0}), n_features_to_select=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=LogisticRegression(class_weight={0: 1.0}), n_features_to_select=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 1.0})</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 1.0})</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RFE(estimator=LogisticRegression(class_weight={0: 1.0}), n_features_to_select=5)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk2QBlcWKO9M",
        "outputId": "468d7b8f-9282-4a16-9392-be8ad2babfa9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'RFE' object has no attribute 'ranking_'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(test_x_onehot\u001b[38;5;241m.\u001b[39mcolumns, \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranking_\u001b[49m))\n\u001b[1;32m      2\u001b[0m feature_importance\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importances:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, feature_importance)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RFE' object has no attribute 'ranking_'"
          ]
        }
      ],
      "source": [
        "feature_importance = list(zip(test_x_onehot.columns, selector.ranking_))\n",
        "feature_importance.sort(key=lambda x: x[1])\n",
        "print(\"Feature importances:\\n\", feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j52MAhdb7YSV"
      },
      "source": [
        "Without class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_LFBgK57XvH",
        "outputId": "ed3d901e-4c88-4400-8a1d-29b5428e300e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  17.6s\n",
            "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=liblinear;, score=0.952 total time=  17.4s\n",
            "[CV 1/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time=  30.7s\n",
            "[CV 2/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time=  51.9s\n",
            "[CV 3/3] END C=9.999999999999999e-05, penalty=l2, solver=lbfgs;, score=0.952 total time= 1.0min\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 1/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  56.4s\n",
            "[CV 2/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  29.1s\n",
            "[CV 3/3] END C=0.000774263682681127, penalty=l2, solver=lbfgs;, score=0.952 total time=  47.5s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 1/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.953 total time=  55.6s\n",
            "[CV 2/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.953 total time=  52.2s\n",
            "[CV 3/3] END C=0.005994842503189409, penalty=l2, solver=lbfgs;, score=0.952 total time=  27.1s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 1/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.6min\n",
            "[CV 2/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.953 total time=  50.4s\n",
            "[CV 3/3] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=0.952 total time=  43.2s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
            "[CV 1/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  37.6s\n",
            "[CV 2/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  25.6s\n",
            "[CV 3/3] END C=0.3593813663804626, penalty=l2, solver=lbfgs;, score=0.952 total time=  28.6s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
            "[CV 1/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.953 total time=  54.8s\n",
            "[CV 2/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.1min\n",
            "[CV 3/3] END C=2.782559402207126, penalty=l2, solver=lbfgs;, score=0.952 total time=  37.0s\n",
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 1/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.952 total time= 1.5min\n",
            "[CV 2/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.953 total time=  38.5s\n",
            "[CV 3/3] END C=21.54434690031882, penalty=l2, solver=lbfgs;, score=0.953 total time=  55.5s\n",
            "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
            "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
            "[CV 1/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.952 total time=  20.9s\n",
            "[CV 2/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.952 total time=  32.8s\n",
            "[CV 3/3] END C=166.81005372000556, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.2min\n",
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.5s\n",
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=liblinear;, score=0.952 total time=  18.6s\n",
            "[CV 1/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.953 total time=  45.2s\n",
            "[CV 2/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.953 total time=  48.1s\n",
            "[CV 3/3] END C=1291.5496650148827, penalty=l2, solver=lbfgs;, score=0.952 total time= 2.3min\n",
            "[CV 1/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.2s\n",
            "[CV 2/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.3s\n",
            "[CV 3/3] END C=10000.0, penalty=l2, solver=liblinear;, score=0.952 total time=  18.4s\n",
            "[CV 1/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.952 total time=  22.6s\n",
            "[CV 2/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.953 total time= 1.1min\n",
            "[CV 3/3] END C=10000.0, penalty=l2, solver=lbfgs;, score=0.952 total time=  19.8s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# 对 dominant_topic 进行独热编码\n",
        "\n",
        "\n",
        "# 标准化\n",
        "scaler = StandardScaler()\n",
        "sentiment_scores = train_x_onehot['sentiment_score'].values.reshape(-1, 1)\n",
        "train_x_onehot['sentiment_score'] = scaler.fit_transform(sentiment_scores)\n",
        "\n",
        "# 将类权重添加到逻辑回归模型\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "# 可能选择更多特征\n",
        "selector = RFE(logistic_model, n_features_to_select=5, step=1)\n",
        "# selector.fit(train_x_onehot, train_y) ##TO CHANGE!\n",
        "grid_search.fit(test_x_onehot, test_y)\n",
        "\n",
        "# 定义要搜索的参数网格\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 10),\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "# 设置GridSearchCV\n",
        "grid_search = GridSearchCV(logistic_model, param_grid, cv=3, scoring='accuracy', verbose=3)\n",
        "# grid_search.fit(train_x_onehot, train_y) ##TO CHANGE!\n",
        "grid_search.fit(test_x_onehot, test_y)\n",
        "\n",
        "# 使用最佳参数的模型\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 预测\n",
        "test_pred = best_model.predict(test_x_onehot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaKLpSD17XrT",
        "outputId": "bb38aaf5-a66c-4d44-ed6c-e0d3ca2b74d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      1.00      0.98   1886055\n",
            "         1.0       0.55      0.04      0.07     95054\n",
            "\n",
            "    accuracy                           0.95   1981109\n",
            "   macro avg       0.75      0.52      0.52   1981109\n",
            "weighted avg       0.93      0.95      0.93   1981109\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1883050    3005]\n",
            " [  91393    3661]]\n"
          ]
        }
      ],
      "source": [
        "# 评估\n",
        "print(\"Classification Report:\\n\", classification_report(test_y, test_pred))\n",
        "conf_matrix = confusion_matrix(test_y, test_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# 评估：ndcg\n",
        "print(\"NDCG@1:\\n\", ndcg_score([test_y], [test_pred], k=1))\n",
        "print(\"NDCG@5:\\n\", ndcg_score([test_y], [test_pred], k=5))\n",
        "print(\"NDCG@10:\\n\", ndcg_score([test_y], [test_pred], k=10))\n",
        "print(\"NDCG:\\n\", ndcg_score([test_y], [test_pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YrxF0-9OgSq"
      },
      "source": [
        "Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLegJxIh8HKd",
        "outputId": "0d91df3b-f329-4bc9-ebab-8df7044ee8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature importances:\n",
            " [('eastmoney_robo_journalism', 1), ('SMA_robo_journalism', 1), ('colon_mark', 1), ('topic_3', 1), ('topic_4', 1), ('topic_0', 2), ('media_robo_journalism', 3), ('topic_1', 4), ('question_mark', 5), ('topic_2', 6), ('exclamation_mark', 7), ('sentiment_score', 8), ('month', 9), ('article_source_cate', 10), ('article_author', 11)]\n"
          ]
        }
      ],
      "source": [
        "feature_importance = list(zip(test_x_onehot.columns, selector.ranking_))\n",
        "feature_importance.sort(key=lambda x: x[1])\n",
        "print(\"Feature importances:\\n\", feature_importance)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "haMqQXwegh7q",
        "toZxlWepyRVA",
        "xxQblqMLVcsU",
        "iPW1-BTAuf_B"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
